#!/usr/bin/env python3
"""
Script de configuraciÃ³n automÃ¡tica para Ollama con SCCA
"""

import subprocess
import time
import sys
import asyncio
import aiohttp

def run_command(command, description):
    """Ejecuta un comando y muestra el resultado"""
    print(f"ğŸ”„ {description}...")
    try:
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        if result.returncode == 0:
            print(f"âœ… {description} - Exitoso")
            return True
        else:
            print(f"âŒ {description} - Error: {result.stderr}")
            return False
    except Exception as e:
        print(f"âŒ {description} - ExcepciÃ³n: {e}")
        return False

async def test_ollama_connection():
    """Prueba la conexiÃ³n con Ollama"""
    print("ğŸ”„ Probando conexiÃ³n con Ollama...")
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get("http://localhost:11434/api/tags", timeout=5) as response:
                if response.status == 200:
                    print("âœ… Ollama estÃ¡ funcionando correctamente")
                    return True
                else:
                    print(f"âŒ Ollama responde con error: {response.status}")
                    return False
    except Exception as e:
        print(f"âŒ No se pudo conectar a Ollama: {e}")
        return False

def main():
    """ConfiguraciÃ³n automÃ¡tica de Ollama"""
    print("ğŸ‹ CONFIGURACIÃ“N AUTOMÃTICA DE OLLAMA PARA SCCA")
    print("=" * 50)
    
    # Verificar si Ollama estÃ¡ instalado
    if not run_command("ollama --version", "Verificando instalaciÃ³n de Ollama"):
        print("\nâŒ Ollama no estÃ¡ instalado.")
        print("ğŸ“¥ Por favor:")
        print("   1. Descarga Ollama desde: https://ollama.com/download/windows")
        print("   2. Instala el archivo OllamaSetup.exe")
        print("   3. Reinicia la terminal")
        print("   4. Ejecuta este script nuevamente")
        return False
    
    print("\nğŸ¯ Ollama detectado. Continuando con la configuraciÃ³n...")
    
    # Verificar si el servidor estÃ¡ ejecutÃ¡ndose
    print("\nğŸ”„ Verificando servidor Ollama...")
    server_running = subprocess.run("tasklist | findstr ollama", shell=True, capture_output=True)
    
    if server_running.returncode != 0:
        print("ğŸš€ Iniciando servidor Ollama...")
        # Iniciar servidor en segundo plano
        subprocess.Popen("ollama serve", shell=True)
        print("â³ Esperando 5 segundos para que el servidor inicie...")
        time.sleep(5)
    else:
        print("âœ… Servidor Ollama ya estÃ¡ ejecutÃ¡ndose")
    
    # Descargar modelo Mistral
    print("\nğŸ“¦ Descargando modelo Mistral (esto puede tomar varios minutos)...")
    if run_command("ollama pull mistral:7b-instruct", "Descargando Mistral 7B Instruct"):
        print("âœ… Modelo Mistral descargado exitosamente")
    else:
        print("âŒ Error descargando modelo. Verifica tu conexiÃ³n a internet.")
        return False
    
    # Probar conexiÃ³n
    print("\nğŸ§ª Probando conexiÃ³n con el modelo...")
    if asyncio.run(test_ollama_connection()):
        print("âœ… ConfiguraciÃ³n completada exitosamente")
        
        print("\nğŸ‰ Â¡OLLAMA CONFIGURADO CORRECTAMENTE!")
        print("=" * 50)
        print("ğŸ“‹ PrÃ³ximos pasos:")
        print("   1. El servidor Ollama estÃ¡ ejecutÃ¡ndose")
        print("   2. El modelo Mistral estÃ¡ descargado")
        print("   3. Ejecuta: python test_system.py")
        print("   4. Â¡Disfruta creando clips automÃ¡ticamente!")
        
        return True
    else:
        print("âŒ Error en la configuraciÃ³n. Revisa los logs arriba.")
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸš€ Ejecuta 'python test_system.py' para verificar todo el sistema")
    else:
        print("\nğŸ“– Consulta el README.md para soluciÃ³n de problemas")